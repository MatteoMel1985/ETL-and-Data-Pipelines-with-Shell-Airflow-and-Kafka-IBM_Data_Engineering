![Skills_Network](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/images/image.png)  

<h1 align="center">Hands-on Lab: Build a Streaming ETL Pipeline using Kafka</h1>

# ***Project Scenario***  

You are a data engineer at a data analytics consulting company. You have been assigned to a project that aims to de-congest the national highways by analyzing the road traffic data from different toll plazas. As a vehicle passes a toll plaza, the vehicle's data like `vehicle_id`, `vehicle_type` , `toll_plaza_id` , and `timestamp` are streamed to Kafka. Your job is to create a data pipe line that collects the streaming data and loads it into a database.  

# ***Objectives***  

In this assignment, you will create a streaming data pipe by performing these steps:

* Start a MySQL database server
* Create a table to hold the toll data
* Start the Kafka server
* Install the Kafka Python driver
* Install the MySQL Python driver
* Create a topic named toll in Kafka
* Download streaming data generator program
* Customize the generator program to steam to toll topic
* Download and customize streaming data consumer
* Customize the consumer program to write into a MySQL database table
* Verify that streamed data is being collected in the database table

## ***Exercise 1: Download and extract Kafka***  

1. Download Kafka by running the command below.

```Bash
wget https://archive.apache.org/dist/kafka/3.7.0/kafka_2.12-3.7.0.tgz
```

2. Extract Kafka from the zip file by running the command below.

```Bash
tar -xzf kafka_2.12-3.7.0.tgz
```

> ***Note***: *This command creates a directory named kafka_2.12-3.7.0 in the current directory*.

## ***Exercise 2: Configure KRaft and start server***  

1. Change to the `kafka_2.12-3.7.0` directory.

```Bash
cd kafka_2.12-3.7.0
```

2. Generate a cluster UUID that will uniquely identify the Kafka cluster.

```Bash
KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"
```

> ***Note***: *The new cluster id generated will be used by the KRaft controller*.


3. KRaft requires the log directories to be configured. Run the following command to configure the log directories passing the cluster id.

```Bash
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties
```

4. Now that KRaft is configured, you can start the Kafka server by running the following command.

```Bash
bin/kafka-server-start.sh config/kraft/server.properties
```

> ***Note***: *You can be sure that the Kafka server started there is information generated that the server started successfully along with some additional messages, such as log loaded*.

![demo_image1](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/aN0HsMMBWXxj8gPhA8BVyg/KafkaStarted.jpg)  

## ***Exercise 3: Start MySQL server and setup the database***  

Open MySQL in IDE by clicking on the purple button, or by clicking on the Explorer icon in the left pane, then select Databases, then MySQL, and finally, click on the Create button.  

![demo_image2](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/fNtJAjB4gJ4wl7wZ_LMKZQ/mysql1.png)  

Once the MySQL server started, select the Connection Information tab. From that, copy the password.  

![demo_image2](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/vlBHbkvNbPoWLHsqFb0w_g/mysql2.png)  

![demo_image3](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/kWttEx8mDuoQZuHR74xZFg/ETL3.png)  

Connect to the MySQL server using the command below in a new terminal. Make sure you use the password given to you when the MySQL server starts. Please make a note of the password because you will need it later.

```Bash
mysql --host=mysql --port=3306 --user=root --password=Replace your password
```

- Create a database named `tolldata`.  

At the **mysql>** prompt, run the command below to create the database.  

```sql
create database tolldata;
```

- Create a table named `livetolldata` with the schema to store the data generated by the traffic simulator.  

Run the following command to create the table:  

```sql
use tolldata;

create table livetolldata(timestamp datetime,vehicle_id int,vehicle_type char(15),toll_plaza_id smallint);
```

> **Note**: *This is the table where you will store all streamed data that comes from Kafka. Each row is a record of when a vehicle has passed through a certain toll plaza along with its type and anonymized id*.

- Disconnect from the MySQL server.  

```Bash
exit
```

## ***Exercise 4: Install the Python packages***  

1. Install the Python module `kafka-python`. This Python module will help you to communicate with kafka server. It can used to send and receive messages from Kafka.

```Python
pip3 install kafka-python
```

2. Install the Python module `mysql-connector-python` using the pip command.

```Python
pip3 install mysql-connector-python==8.0.31
```

This Python module will help you to interact with MySQL server.  


## ***Exercise 5: Create data pipeline for toll data***  

1. Create a Kafka topic named `toll`:

  * Change directory into `kafka_2.12-3.7.0`.

```bash
cd kafka_2.12-3.7.0
```

  * Verify if `kafka-topics.sh` exist by running

```bash
ls bin
```

> You should be able to see `kafka-topics.sh` among the many files in the output.

  * Finally, create the topic

```bash
bin/kafka-topics.sh --create --topic toll --bootstrap-server localhost:9092
```

The output in terminal should be `Created topic toll.`.  

2. Download the `toll_traffic_generator.py` from the url given below using wget.

```bash
wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/toll_traffic_generator.py
```

3. Open the code using the editor using the **“Menu –> File –>Open”** option (or go to **Explorer pane > kafka_2.12-3.7.0 > `toll_traffic_generator.py`**).

4. Open the `toll_traffic_generator.py` and set the topic to `toll` (on line 9, you will see `TOPIC = 'set your topic here'`).

5. Run the `toll_traffic_generator.py`

```Python
python3 toll_traffic_generator.py
```

You should now see a continuous list of information appearing in the terminal.  

6. Open a new terminal and download the `streaming-data-reader.py` from the URL below using wget.

```bash
wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/vVxmU5uatDowvAIKRZrFjg/streaming-data-reader.py
```

7. Open the `streaming-data-reader.py` (as you did with `toll_traffic_generator.py`) and modify the following details so that the program can connect to your MySQL server.

`TOPIC='toll'`
`DATABASE = 'tolldata'`
`USERNAME = 'root'`
`PASSWORD = 'Insert_Your_MySQL_Password'`  

8. Run the `streaming-data-reader.py.`

```Bash
python3 streaming-data-reader.py
```

9. If you completed all the steps correctly, the streaming toll data will get stored in the table `livetolldata`. As a last step in this lab, open mysql CLI and list the top 10 rows in the table `livetolldata`. To do so:

* Open a new terminal.

* Connect to MySQL as done before:

```Bash
mysql --host=mysql --port=3306 --user=root --password='insert_your_password'
```

 You should see the prompt becoming like `mysql>`  

 * Select the database

```sql
USE tolldata;
```

You should now see the output `Database changed`.  

* To list the top 10 rows from `livetolldata` launch the following command:

```sql
SELECT * FROM livetolldata LIMIT 10;
```

Following is my output with my current timestamp:

| timestamp           | vehicle_id | vehicle_type | toll_plaza_id |
+---------------------+------------+--------------+---------------+
| 2026-01-28 08:40:23 |    5732438 | truck        |          4010 |
| 2026-01-28 08:40:25 |    6871172 | truck        |          4001 |
| 2026-01-28 08:40:25 |     486364 | car          |          4001 |
| 2026-01-28 08:40:26 |    7888747 | car          |          4002 |
| 2026-01-28 08:40:27 |    9684981 | car          |          4006 |
| 2026-01-28 08:40:27 |     230427 | car          |          4001 |
| 2026-01-28 08:40:28 |    4167477 | car          |          4000 |
| 2026-01-28 08:40:29 |    5888276 | car          |          4000 |
| 2026-01-28 08:40:29 |    3206569 | car          |          4010 |
| 2026-01-28 08:40:30 |    2369011 | car          |          4002 |
+---------------------+------------+--------------+---------------+  

## Stop the producer  

In the terminal where you are running producer, press CTRL+C.  

## Stop the consumer  

In the terminal where you are running consumer, press CTRL+C.  

# Author
# ***[Matteo Meloni](https://www.linkedin.com/in/matteo-meloni-40a357154/)***
